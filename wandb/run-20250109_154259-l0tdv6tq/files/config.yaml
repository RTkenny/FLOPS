_wandb:
    value:
        cli_version: 0.19.2
        m: []
        python_version: 3.9.19
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 98
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 55
                - 71
                - 98
            "3":
                - 23
                - 55
            "4": 3.9.19
            "5": 0.19.2
            "6": 4.45.2
            "8":
                - 5
            "12": 0.19.2
            "13": linux-x86_64
flops_config:
    value:
        accelerator_config:
            dispatch_batches: null
            even_batches: true
            gradient_accumulation_kwargs: null
            non_blocking: false
            split_batches: false
            use_configured_state: false
            use_seedable_sampler: true
        adafactor: false
        adam_beta1: 0.9
        adam_beta2: 0.999
        adam_epsilon: 1e-08
        auto_find_batch_size: false
        batch_eval_metrics: false
        bf16: false
        bf16_full_eval: false
        data_seed: null
        dataloader_drop_last: false
        dataloader_num_workers: 0
        dataloader_persistent_workers: false
        dataloader_pin_memory: true
        dataloader_prefetch_factor: null
        dataset: ImageNet
        ddp_backend: null
        ddp_broadcast_buffers: null
        ddp_bucket_cap_mb: null
        ddp_find_unused_parameters: null
        ddp_timeout: 1800
        debug: []
        deepspeed: null
        device: cuda
        disable_tqdm: false
        dispatch_batches: null
        do_eval: false
        do_predict: false
        do_train: false
        epochs: 10
        eval_accumulation_steps: null
        eval_delay: 0
        eval_do_concat_batches: true
        eval_on_start: false
        eval_steps: null
        eval_strategy: "no"
        eval_use_gather_object: false
        evaluation_strategy: null
        fp16: false
        fp16_backend: auto
        fp16_full_eval: false
        fp16_opt_level: O1
        fsdp: []
        fsdp_config:
            min_num_params: 0
            xla: false
            xla_fsdp_grad_ckpt: false
            xla_fsdp_v2: false
        fsdp_min_num_params: 0
        fsdp_transformer_layer_cls_to_wrap: null
        full_determinism: false
        gradient_accumulation_steps: 1
        gradient_checkpointing: false
        gradient_checkpointing_kwargs: null
        gradient_estimation_strategy: bp
        greater_is_better: null
        group_by_length: false
        half_precision_backend: auto
        hub_always_push: false
        hub_model_id: null
        hub_private_repo: false
        hub_strategy: every_save
        hub_token: <HUB_TOKEN>
        ignore_data_skip: false
        include_inputs_for_metrics: false
        include_num_input_tokens_seen: false
        include_tokens_per_second: false
        is_grad_clip: false
        is_log: false
        jit_mode_eval: false
        label_names: null
        label_smoothing_factor: 0
        learning_rate: 0.001
        length_column_name: length
        load_best_model_at_end: false
        local_rank: -1
        log_interval: 10
        log_level: passive
        log_level_replica: warning
        log_on_each_node: true
        log_with: wandb
        logging_dir: ./output/mlp/runs/Jan09_15-42-57_zkti
        logging_first_step: false
        logging_nan_inf_filter: true
        logging_steps: 500
        logging_strategy: steps
        lr_scheduler_type: linear
        max_grad_norm: 1
        max_steps: -1
        metric_for_best_model: null
        mp_parameters: ""
        neftune_noise_alpha: null
        no_cuda: false
        num_train_epochs: 3
        optim: adamw_torch
        optim_args: null
        optim_target_modules: null
        output_dir: ./output/mlp
        overwrite_output_dir: false
        past_index: -1
        per_device_eval_batch_size: 64
        per_device_train_batch_size: 64
        per_gpu_eval_batch_size: null
        per_gpu_train_batch_size: null
        prediction_loss_only: false
        push_to_hub: false
        push_to_hub_model_id: null
        push_to_hub_organization: null
        push_to_hub_token: <PUSH_TO_HUB_TOKEN>
        ray_scope: last
        remove_unused_columns: true
        report_to:
            - tensorboard
            - wandb
        restore_callback_states_from_checkpoint: false
        resume_from_checkpoint: null
        run_name: ./output/mlp
        sample_n: 10
        save_on_each_node: false
        save_only_model: false
        save_safetensors: true
        save_steps: 500
        save_strategy: steps
        save_total_limit: null
        seed: 42
        skip_memory_metrics: true
        split_batches: null
        tf32: null
        torch_compile: false
        torch_compile_backend: null
        torch_compile_mode: null
        torch_empty_cache_steps: null
        torchdynamo: null
        tpu_metrics_debug: false
        tpu_num_cores: null
        tracker_project_name: flops
        use_cpu: false
        use_ipex: false
        use_legacy_prediction_loop: false
        use_liger_kernel: false
        use_mps_device: false
        warmup_ratio: 0
        warmup_steps: 0
        weight_decay: 0
        zo_eps: 0.001
